DEBUG:root:network : controlled_VQVAE
cuda_device : 1
seed : 0
spv_proportion : 100
truncated : False
act_size : 8
personality_size : 0
value_codebook_vocab : False
sample : top
domain : e2e
dialog_path : data/dialogue/e2e-dataset/train.json
test_dialog_path : data/dialogue/e2e-dataset/test.json
dev_dialog_path : data/dialogue/e2e-dataset/dev.json
slot_path : data/dialogue/e2e-dataset/slot_value.json
slot_max_ts : 21
text_max_ts : 82
slot_value_size : {'name': 1, 'eatType': 3, 'priceRange': 6, 'customer rating': 6, 'near': 1, 'food': 7, 'area': 2, 'familyFriendly': 2}
condition_size : 36
key_order : ['area', 'customer rating', 'eatType', 'familyFriendly', 'food', 'name', 'near', 'priceRange']
split : None
python_path : /home/huxu/anaconda3/envs/p3-torch13/bin/python
decoder_network : LSTM
various_go : False
commitment_cost : 0.25
grad_clip_norm : 1.0
max_turn : 200
emb_size : 300
emb_trainable : True
hidden_size : 300
codebook_size : 2048
lr : 0.001
lr_decay : 1.0
batch_size : 512
dropout_rate : 0.0
epoch_num : 1
cuda : True
early_stop_count : 30
vocab_size : None
remove_slot_value : False
encoder_layer_num : 3
beam_search : False
beam_size : 10
beam_len_bonus : 0.5
teacher_force : 50
glove_path : ./data/glove.840B.300d.txt
model_path : ./models/controlled_VQVAE_e2e_LSTM_VCBFalse_CB2048EL3BS512CC0d25Stop.pkl
result_path : ./results/controlled_VQVAE_e2e_LSTM_VCBFalse_CB2048EL3BS512CC0d25StopTMT82.csv
vocab_emb : ./vocabs/embedding_e2e.npy
vocab_path : ./vocabs/e2e.p

DEBUG:root:Device: 1
INFO:root:total trainable params: 33133343
INFO:root:Controlled_VQVAE(
  (vae_encoder): LSTMDynamicEncoder(
    (embedding): Embedding(2949, 300)
    (lstm): LSTM(300, 300, num_layers=3, bidirectional=True)
  )
  (vocab_vq_vae): Vocab_VectorQuantizer(
    (embedding): Embedding(2949, 300)
  )
  (encoder): LSTMDynamicEncoder(
    (embedding): Embedding(2949, 300)
    (lstm): LSTM(300, 300, num_layers=3, bidirectional=True)
  )
  (act_vq_vae): VectorQuantizer(
    (_embedding): Embedding(2048, 300)
  )
  (value_vq_vae): VectorQuantizer(
    (_embedding): Embedding(2048, 300)
  )
  (decoder): Attn_RNN_Decoder(
    (emb): Embedding(2949, 300)
    (a_attn): Attn(
      (attn): Linear(in_features=1200, out_features=600, bias=True)
    )
    (p_attn): Attn(
      (attn): Linear(in_features=1200, out_features=600, bias=True)
    )
    (rnn): LSTM(1500, 600)
    (emb_proj): Linear(in_features=600, out_features=300, bias=True)
    (proj): Linear(in_features=300, out_features=2949, bias=True)
  )
  (act_predictor): MultiLabel_Classification(
    (linear1): Linear(in_features=300, out_features=150, bias=True)
    (linear2): Linear(in_features=150, out_features=8, bias=True)
  )
  (act_mlp): MLP(
    (linear1): Linear(in_features=600, out_features=1200, bias=True)
    (linear2): Linear(in_features=1200, out_features=300, bias=True)
  )
  (value_predictor): ModuleList(
    (0): MultiClass_Classification(
      (linear1): Linear(in_features=300, out_features=150, bias=True)
      (linear2): Linear(in_features=150, out_features=3, bias=True)
    )
    (1): MultiClass_Classification(
      (linear1): Linear(in_features=300, out_features=150, bias=True)
      (linear2): Linear(in_features=150, out_features=7, bias=True)
    )
    (2): MultiClass_Classification(
      (linear1): Linear(in_features=300, out_features=150, bias=True)
      (linear2): Linear(in_features=150, out_features=4, bias=True)
    )
    (3): MultiClass_Classification(
      (linear1): Linear(in_features=300, out_features=150, bias=True)
      (linear2): Linear(in_features=150, out_features=3, bias=True)
    )
    (4): MultiClass_Classification(
      (linear1): Linear(in_features=300, out_features=150, bias=True)
      (linear2): Linear(in_features=150, out_features=8, bias=True)
    )
    (5): MultiClass_Classification(
      (linear1): Linear(in_features=300, out_features=150, bias=True)
      (linear2): Linear(in_features=150, out_features=2, bias=True)
    )
    (6): MultiClass_Classification(
      (linear1): Linear(in_features=300, out_features=150, bias=True)
      (linear2): Linear(in_features=150, out_features=2, bias=True)
    )
    (7): MultiClass_Classification(
      (linear1): Linear(in_features=300, out_features=150, bias=True)
      (linear2): Linear(in_features=150, out_features=7, bias=True)
    )
  )
  (value_mlp): ModuleList(
    (0): MLP(
      (linear1): Linear(in_features=600, out_features=1200, bias=True)
      (linear2): Linear(in_features=1200, out_features=300, bias=True)
    )
    (1): MLP(
      (linear1): Linear(in_features=600, out_features=1200, bias=True)
      (linear2): Linear(in_features=1200, out_features=300, bias=True)
    )
    (2): MLP(
      (linear1): Linear(in_features=600, out_features=1200, bias=True)
      (linear2): Linear(in_features=1200, out_features=300, bias=True)
    )
    (3): MLP(
      (linear1): Linear(in_features=600, out_features=1200, bias=True)
      (linear2): Linear(in_features=1200, out_features=300, bias=True)
    )
    (4): MLP(
      (linear1): Linear(in_features=600, out_features=1200, bias=True)
      (linear2): Linear(in_features=1200, out_features=300, bias=True)
    )
    (5): MLP(
      (linear1): Linear(in_features=600, out_features=1200, bias=True)
      (linear2): Linear(in_features=1200, out_features=300, bias=True)
    )
    (6): MLP(
      (linear1): Linear(in_features=600, out_features=1200, bias=True)
      (linear2): Linear(in_features=1200, out_features=300, bias=True)
    )
    (7): MLP(
      (linear1): Linear(in_features=600, out_features=1200, bias=True)
      (linear2): Linear(in_features=1200, out_features=300, bias=True)
    )
  )
  (dec_loss): NLLLoss()
)
INFO:root:embedding.  mean: 0.000694  std 0.504608
DEBUG:root:bucket 1 instance 42061
DEBUG:root:loss:73.01904296875 reconloss:7.987807273864746 actloss:0.6945152282714844 otherloss:10.941596984863281 actvqloss:0.001871535205282271 othervqloss:0.01507720910012722 grad:5.548280172034563
DEBUG:root:loss:67.24566650390625 reconloss:7.955278396606445 actloss:0.693336009979248 otherloss:10.929929733276367 actvqloss:0.0064804754219949245 othervqloss:0.06283983588218689 grad:5.829124115496358
DEBUG:root:loss:55.633113861083984 reconloss:7.902877330780029 actloss:0.6925108432769775 otherloss:10.903949737548828 actvqloss:0.044915348291397095 othervqloss:0.5252535343170166 grad:6.658662174843558
DEBUG:root:loss:45.56700897216797 reconloss:7.656704902648926 actloss:0.6919179558753967 otherloss:10.888269424438477 actvqloss:0.23750683665275574 othervqloss:3.296163320541382 grad:9.475754237654716
DEBUG:root:loss:56.663360595703125 reconloss:7.129976749420166 actloss:0.690841794013977 otherloss:10.86483383178711 actvqloss:0.9545811414718628 othervqloss:15.274993896484375 grad:13.913780129116725
DEBUG:root:loss:93.61075592041016 reconloss:6.755216121673584 actloss:0.6910736560821533 otherloss:10.839844703674316 actvqloss:2.008756637573242 othervqloss:55.52820587158203 grad:15.618722881126146
DEBUG:root:loss:188.52862548828125 reconloss:6.538295745849609 actloss:0.6894450187683105 otherloss:10.820636749267578 actvqloss:2.3786423206329346 othervqloss:153.57742309570312 grad:19.491760147576123
DEBUG:root:loss:375.37969970703125 reconloss:6.434720039367676 actloss:0.6893883347511292 otherloss:10.788932800292969 actvqloss:2.0772438049316406 othervqloss:341.02947998046875 grad:24.363088947360556
DEBUG:root:loss:615.4124755859375 reconloss:6.338036060333252 actloss:0.6880290508270264 otherloss:10.76729965209961 actvqloss:1.3728283643722534 othervqloss:582.3136596679688 grad:28.163925465377165
DEBUG:root:loss:839.6761474609375 reconloss:6.215281009674072 actloss:0.6873030662536621 otherloss:10.74479866027832 actvqloss:0.7529494166374207 othervqloss:806.8594360351562 grad:30.717812376366503
DEBUG:root:loss:1022.6987915039062 reconloss:5.996774196624756 actloss:0.6867039203643799 otherloss:10.712369918823242 actvqloss:0.39811235666275024 othervqloss:990.161376953125 grad:26.317989689678818
DEBUG:root:loss:1177.5064697265625 reconloss:5.729794025421143 actloss:0.6865074634552002 otherloss:10.687750816345215 actvqloss:0.2820565700531006 othervqloss:1146.2664794921875 grad:24.65215737409161
DEBUG:root:loss:1344.730224609375 reconloss:5.429234504699707 actloss:0.6864441633224487 otherloss:10.645835876464844 actvqloss:0.30798736214637756 othervqloss:1314.073486328125 grad:25.365555802111448
DEBUG:root:loss:1418.9599609375 reconloss:5.192852973937988 actloss:0.6854519844055176 otherloss:10.599233627319336 actvqloss:0.45512256026268005 othervqloss:1388.7041015625 grad:29.900063198684425
DEBUG:root:loss:1450.4256591796875 reconloss:4.993283748626709 actloss:0.6847012042999268 otherloss:10.542364120483398 actvqloss:0.7083931565284729 othervqloss:1419.9327392578125 grad:30.58753299599944
DEBUG:root:loss:1435.1136474609375 reconloss:4.871438980102539 actloss:0.6842774152755737 otherloss:10.508267402648926 actvqloss:1.0091712474822998 othervqloss:1404.963623046875 grad:29.357064104332984
DEBUG:root:loss:1461.601806640625 reconloss:4.721041679382324 actloss:0.6838988661766052 otherloss:10.444501876831055 actvqloss:1.24372136592865 othervqloss:1431.25927734375 grad:36.172660939926075
DEBUG:root:loss:1522.3917236328125 reconloss:4.669700622558594 actloss:0.6832281947135925 otherloss:10.420360565185547 actvqloss:1.3294010162353516 othervqloss:1492.467041015625 grad:49.43471477369408
DEBUG:root:loss:1630.04833984375 reconloss:4.638878345489502 actloss:0.6826331615447998 otherloss:10.343709945678711 actvqloss:1.3119243383407593 othervqloss:1600.18212890625 grad:75.2074986596618
DEBUG:root:loss:1792.428466796875 reconloss:4.6013569831848145 actloss:0.6822845935821533 otherloss:10.283151626586914 actvqloss:1.238712191581726 othervqloss:1763.444580078125 grad:85.56740898058095
DEBUG:root:loss:1993.4361572265625 reconloss:4.5690083503723145 actloss:0.6811693906784058 otherloss:10.209949493408203 actvqloss:1.1434680223464966 othervqloss:1964.6661376953125 grad:102.77521245989888
DEBUG:root:loss:2223.302001953125 reconloss:4.570433139801025 actloss:0.6810783743858337 otherloss:10.167119979858398 actvqloss:1.060542106628418 othervqloss:2194.99951171875 grad:112.1607427376362
DEBUG:root:loss:2408.697509765625 reconloss:4.514880180358887 actloss:0.6810291409492493 otherloss:10.065646171569824 actvqloss:0.9601427316665649 othervqloss:2380.830078125 grad:78.42561818166256
DEBUG:root:loss:2636.06201171875 reconloss:4.534808158874512 actloss:0.6807960271835327 otherloss:10.0210599899292 actvqloss:0.8706260919570923 othervqloss:2608.3994140625 grad:287.8694094421719
DEBUG:root:loss:2892.15966796875 reconloss:4.471680641174316 actloss:0.6801811456680298 otherloss:9.979268074035645 actvqloss:0.7933651208877563 othervqloss:2864.76171875 grad:118.61920166685688
DEBUG:root:loss:3053.88134765625 reconloss:4.498195171356201 actloss:0.6793726682662964 otherloss:9.965675354003906 actvqloss:0.7306150197982788 othervqloss:3026.51953125 grad:399.24002189147956
DEBUG:root:loss:3266.358642578125 reconloss:4.468608856201172 actloss:0.6791794896125793 otherloss:9.887039184570312 actvqloss:0.6840600967407227 othervqloss:3239.2236328125 grad:126.33522290342655
DEBUG:root:loss:3422.01904296875 reconloss:4.4661455154418945 actloss:0.6786497235298157 otherloss:9.834746360778809 actvqloss:0.6592404842376709 othervqloss:3394.927490234375 grad:169.71281557959216
DEBUG:root:loss:3679.095703125 reconloss:4.4292073249816895 actloss:0.6787680983543396 otherloss:9.791409492492676 actvqloss:0.6500241756439209 othervqloss:3652.25537109375 grad:104.34272487542243
DEBUG:root:loss:3790.5517578125 reconloss:4.432013034820557 actloss:0.6788989305496216 otherloss:9.705595970153809 actvqloss:0.655903160572052 othervqloss:3763.439453125 grad:71.30063175213287
DEBUG:root:loss:3910.480712890625 reconloss:4.434966087341309 actloss:0.6777258515357971 otherloss:9.703885078430176 actvqloss:0.6791945695877075 othervqloss:3883.72998046875 grad:120.96251846208882
DEBUG:root:loss:4034.161865234375 reconloss:4.408682346343994 actloss:0.6782564520835876 otherloss:9.641654968261719 actvqloss:0.7128345966339111 othervqloss:4007.6591796875 grad:105.23176715535605
DEBUG:root:loss:4079.27978515625 reconloss:4.400044918060303 actloss:0.6781259775161743 otherloss:9.59223461151123 actvqloss:0.7669907212257385 othervqloss:4052.7451171875 grad:83.48718778743374
DEBUG:root:loss:3904.833251953125 reconloss:4.435557842254639 actloss:0.6770317554473877 otherloss:9.516216278076172 actvqloss:0.8279039859771729 othervqloss:3877.922607421875 grad:90.26870037574997
DEBUG:root:loss:3604.686767578125 reconloss:4.460681438446045 actloss:0.6757532358169556 otherloss:9.455885887145996 actvqloss:0.89476478099823 othervqloss:3578.21533203125 grad:88.24337151656763
DEBUG:root:loss:3169.475341796875 reconloss:4.4124627113342285 actloss:0.6767654418945312 otherloss:9.401922225952148 actvqloss:0.9544411897659302 othervqloss:3143.350341796875 grad:68.76470865338213
DEBUG:root:loss:2858.330078125 reconloss:4.393064975738525 actloss:0.6767252683639526 otherloss:9.323237419128418 actvqloss:1.0143972635269165 othervqloss:2832.4287109375 grad:110.48787573809243
DEBUG:root:loss:2539.0751953125 reconloss:4.42223596572876 actloss:0.6759420037269592 otherloss:9.285416603088379 actvqloss:1.0427309274673462 othervqloss:2513.12939453125 grad:36.714548438225684
DEBUG:root:loss:2236.1650390625 reconloss:4.3838090896606445 actloss:0.675456166267395 otherloss:9.274365425109863 actvqloss:1.0292394161224365 othervqloss:2210.53759765625 grad:43.825989924365544
DEBUG:root:loss:1878.171142578125 reconloss:4.399754524230957 actloss:0.6749058961868286 otherloss:9.296457290649414 actvqloss:1.0123748779296875 othervqloss:1852.466064453125 grad:37.59130669031856
DEBUG:root:loss:1559.3936767578125 reconloss:4.401701927185059 actloss:0.6747892498970032 otherloss:9.138886451721191 actvqloss:1.006712794303894 othervqloss:1534.093505859375 grad:34.64062679620677
DEBUG:root:loss:1228.75048828125 reconloss:4.415749549865723 actloss:0.6745925545692444 otherloss:9.16057014465332 actvqloss:1.0323635339736938 othervqloss:1203.4384765625 grad:39.350582219528974
DEBUG:root:loss:960.348388671875 reconloss:4.37286376953125 actloss:0.6736464500427246 otherloss:9.11007308959961 actvqloss:1.1051814556121826 othervqloss:935.1884765625 grad:30.341960366356165
DEBUG:root:loss:735.4713134765625 reconloss:4.397116661071777 actloss:0.6738821268081665 otherloss:9.138469696044922 actvqloss:1.1714575290679932 othervqloss:710.1846923828125 grad:42.25756011742651
DEBUG:root:loss:558.212890625 reconloss:4.380371570587158 actloss:0.6731228828430176 otherloss:9.007487297058105 actvqloss:1.23822820186615 othervqloss:533.1644897460938 grad:43.502255167841334
DEBUG:root:loss:405.2840576171875 reconloss:4.364285469055176 actloss:0.6720396280288696 otherloss:8.988592147827148 actvqloss:1.2612767219543457 othervqloss:380.2683410644531 grad:47.11860193285124
DEBUG:root:loss:301.7126770019531 reconloss:4.406536102294922 actloss:0.671380877494812 otherloss:8.986530303955078 actvqloss:1.2653385400772095 othervqloss:276.6491394042969 grad:40.88874513779436
DEBUG:root:loss:247.37216186523438 reconloss:4.402634620666504 actloss:0.6701172590255737 otherloss:9.033782958984375 actvqloss:1.2438832521438599 othervqloss:222.24534606933594 grad:43.29059124932143
DEBUG:root:loss:196.50552368164062 reconloss:4.38153076171875 actloss:0.6694878935813904 otherloss:8.933935165405273 actvqloss:1.2175904512405396 othervqloss:171.6304931640625 grad:43.17724800615497
DEBUG:root:loss:188.9950714111328 reconloss:4.40369987487793 actloss:0.6688180565834045 otherloss:9.013115882873535 actvqloss:1.199894905090332 othervqloss:163.92123413085938 grad:117.85183226088195
DEBUG:root:loss:174.08932495117188 reconloss:4.346375942230225 actloss:0.6680060029029846 otherloss:9.152034759521484 actvqloss:1.2093485593795776 othervqloss:148.81146240234375 grad:216.2518117900483
DEBUG:root:loss:153.16299438476562 reconloss:4.363544940948486 actloss:0.667756199836731 otherloss:9.350975036621094 actvqloss:1.2496659755706787 othervqloss:127.43629455566406 grad:124.89155665022257
DEBUG:root:loss:134.19778442382812 reconloss:4.342339992523193 actloss:0.6671286225318909 otherloss:9.421710968017578 actvqloss:1.3450826406478882 othervqloss:108.23866271972656 grad:109.42006235425758
DEBUG:root:loss:142.02401733398438 reconloss:4.334342002868652 actloss:0.6649023294448853 otherloss:8.903722763061523 actvqloss:1.4222290515899658 othervqloss:117.02237701416016 grad:161.5279450715177
DEBUG:root:loss:177.3221435546875 reconloss:4.35786247253418 actloss:0.6644744873046875 otherloss:8.919644355773926 actvqloss:1.5071899890899658 othervqloss:152.16314697265625 grad:99.4732281872056
DEBUG:root:loss:229.88888549804688 reconloss:4.376957893371582 actloss:0.6641305088996887 otherloss:8.880157470703125 actvqloss:1.5900628566741943 othervqloss:204.69583129882812 grad:93.88169694786576
DEBUG:root:loss:301.3276062011719 reconloss:4.373120307922363 actloss:0.664021372795105 otherloss:8.888152122497559 actvqloss:1.6754021644592285 othervqloss:276.06561279296875 grad:165.09148891179117
DEBUG:root:loss:407.32916259765625 reconloss:4.365420818328857 actloss:0.6626223921775818 otherloss:8.839614868164062 actvqloss:1.7316577434539795 othervqloss:382.0895690917969 grad:122.70669087553303
DEBUG:root:loss:500.1550598144531 reconloss:4.3503570556640625 actloss:0.6616625785827637 otherloss:8.75322437286377 actvqloss:1.810831904411316 othervqloss:475.0563049316406 grad:249.63698291983656
DEBUG:root:loss:628.4126586914062 reconloss:4.344294548034668 actloss:0.661434531211853 otherloss:8.761945724487305 actvqloss:1.9364560842514038 othervqloss:603.1837158203125 grad:146.72371463864127
DEBUG:root:loss:660.7139892578125 reconloss:4.350651264190674 actloss:0.6606761813163757 otherloss:8.793018341064453 actvqloss:2.039090156555176 othervqloss:635.3374633789062 grad:126.35854511708722
DEBUG:root:loss:798.534912109375 reconloss:4.383732795715332 actloss:0.6597656011581421 otherloss:8.634710311889648 actvqloss:2.158639907836914 othervqloss:773.314697265625 grad:249.5858562819152
DEBUG:root:loss:879.8441162109375 reconloss:4.342630386352539 actloss:0.6575721502304077 otherloss:8.722198486328125 actvqloss:2.2148332595825195 othervqloss:854.4530029296875 grad:157.69534346319233
DEBUG:root:loss:991.0753173828125 reconloss:4.322806358337402 actloss:0.656903088092804 otherloss:8.711851119995117 actvqloss:2.2221622467041016 othervqloss:965.7120971679688 grad:418.69104758830025
DEBUG:root:loss:1192.2559814453125 reconloss:4.388707160949707 actloss:0.6566636562347412 otherloss:8.765609741210938 actvqloss:2.204558849334717 othervqloss:1166.73046875 grad:538.1512821836347
DEBUG:root:loss:1270.0999755859375 reconloss:4.355485916137695 actloss:0.655210554599762 otherloss:8.874982833862305 actvqloss:2.231900215148926 othervqloss:1244.3447265625 grad:370.3875908467175
DEBUG:root:loss:1162.5723876953125 reconloss:4.351692199707031 actloss:0.6541827321052551 otherloss:8.819077491760254 actvqloss:2.290318489074707 othervqloss:1136.901123046875 grad:334.2008228361379
DEBUG:root:loss:1184.406494140625 reconloss:4.386161804199219 actloss:0.6529779434204102 otherloss:8.740846633911133 actvqloss:2.3277173042297363 othervqloss:1158.837646484375 grad:365.8648685763835
DEBUG:root:loss:1079.362548828125 reconloss:4.320630073547363 actloss:0.6529456973075867 otherloss:8.780739784240723 actvqloss:2.3847804069519043 othervqloss:1053.712646484375 grad:272.67924835144765
DEBUG:root:loss:1159.3619384765625 reconloss:4.332546710968018 actloss:0.6516720652580261 otherloss:8.78056526184082 actvqloss:2.3809540271759033 othervqloss:1133.7130126953125 grad:323.36168681504984
DEBUG:root:loss:1144.7703857421875 reconloss:4.363636016845703 actloss:0.6514366865158081 otherloss:8.69056224822998 actvqloss:2.305931568145752 othervqloss:1119.3333740234375 grad:338.1628178500058
DEBUG:root:loss:1018.5079345703125 reconloss:4.340926170349121 actloss:0.652512788772583 otherloss:8.708749771118164 actvqloss:2.3258285522460938 othervqloss:993.0418701171875 grad:238.94777871682615
DEBUG:root:loss:847.7120971679688 reconloss:4.3325114250183105 actloss:0.6506015062332153 otherloss:8.723462104797363 actvqloss:2.3277053833007812 othervqloss:822.2337646484375 grad:246.76265811589502
DEBUG:root:loss:913.4201049804688 reconloss:4.356398582458496 actloss:0.6504033207893372 otherloss:8.60319709777832 actvqloss:2.4035024642944336 othervqloss:888.0780029296875 grad:266.3387750567673
DEBUG:root:loss:998.243896484375 reconloss:4.3144025802612305 actloss:0.6508443355560303 otherloss:8.628992080688477 actvqloss:2.4312539100646973 othervqloss:972.8451538085938 grad:306.6502468962981
DEBUG:root:loss:981.0846557617188 reconloss:4.326554775238037 actloss:0.6500201225280762 otherloss:8.625191688537598 actvqloss:2.525928258895874 othervqloss:955.6010131835938 grad:487.1324740844147
DEBUG:root:loss:564.8530883789062 reconloss:4.32857608795166 actloss:0.6485573053359985 otherloss:8.624720573425293 actvqloss:2.8409156799316406 othervqloss:539.0687255859375 grad:224.13556662681282
DEBUG:root:loss:612.7431640625 reconloss:4.328887462615967 actloss:0.6474207639694214 otherloss:8.611432075500488 actvqloss:2.87306547164917 othervqloss:586.9436645507812 grad:490.9919298071835
DEBUG:root:loss:466.1155700683594 reconloss:4.316637992858887 actloss:0.648831844329834 otherloss:8.530061721801758 actvqloss:2.971179723739624 othervqloss:440.4090881347656 grad:159.01992782582025
DEBUG:root:loss:343.22296142578125 reconloss:4.316762447357178 actloss:0.6472870111465454 otherloss:8.621719360351562 actvqloss:3.0781052112579346 othervqloss:317.21575927734375 grad:131.7588856461982
DEBUG:root:loss:291.1280212402344 reconloss:4.313663959503174 actloss:0.6454979777336121 otherloss:8.642147064208984 actvqloss:3.04093337059021 othervqloss:265.1206359863281 grad:230.57752799418927
DEBUG:root:loss:212.30311584472656 reconloss:4.371392250061035 actloss:0.6454668045043945 otherloss:8.658447265625 actvqloss:3.084152936935425 othervqloss:186.1475067138672 grad:106.95206412408142
INFO:root:Traning time: 68.96525979042053
INFO:root:avg training loss in epoch 0 sup:1295.721372
DEBUG:root:bucket 1 instance 4672
DEBUG:root:loss:101.5174331665039 reconloss:4.290365695953369 actloss:0.6472382545471191 actvqloss:3.2838635444641113
DEBUG:root:loss:106.03263092041016 reconloss:4.303195953369141 actloss:0.6502125263214111 actvqloss:3.3325743675231934
DEBUG:root:loss:110.47517395019531 reconloss:4.264851093292236 actloss:0.6482887268066406 actvqloss:3.3260107040405273
DEBUG:root:loss:106.56170654296875 reconloss:4.286367416381836 actloss:0.6509360074996948 actvqloss:3.335232973098755
DEBUG:root:loss:101.39183044433594 reconloss:4.2853522300720215 actloss:0.6492008566856384 actvqloss:3.3208682537078857
DEBUG:root:loss:108.665283203125 reconloss:4.317831516265869 actloss:0.6494953632354736 actvqloss:3.319319248199463
DEBUG:root:loss:108.52519989013672 reconloss:4.284695625305176 actloss:0.650364339351654 actvqloss:3.3573169708251953
DEBUG:root:loss:111.83689880371094 reconloss:4.304337978363037 actloss:0.648383378982544 actvqloss:3.3097620010375977
DEBUG:root:loss:105.02336883544922 reconloss:4.300859451293945 actloss:0.6491743922233582 actvqloss:3.32273268699646
INFO:root:validation loss in epoch 0 sup:106.669947 unsup:0.000000
INFO:root:time for epoch 0: 72.893876
DEBUG:root:bucket 1 instance 4672
DEBUG:root:loss:111.83906555175781 reconloss:4.303675174713135 actloss:0.648383378982544 actvqloss:3.3097620010375977
DEBUG:root:loss:101.50748443603516 reconloss:4.29169225692749 actloss:0.6472382545471191 actvqloss:3.2838635444641113
DEBUG:root:loss:105.03546905517578 reconloss:4.300654411315918 actloss:0.6491743922233582 actvqloss:3.32273268699646
DEBUG:root:loss:110.46595764160156 reconloss:4.267375469207764 actloss:0.6482887268066406 actvqloss:3.3260107040405273
DEBUG:root:loss:106.03364562988281 reconloss:4.300827503204346 actloss:0.6502125263214111 actvqloss:3.3325743675231934
DEBUG:root:loss:101.3824462890625 reconloss:4.286351680755615 actloss:0.6492008566856384 actvqloss:3.3208682537078857
DEBUG:root:loss:106.57312774658203 reconloss:4.283016204833984 actloss:0.6509360074996948 actvqloss:3.335232973098755
DEBUG:root:loss:108.65444946289062 reconloss:4.316404819488525 actloss:0.6494953632354736 actvqloss:3.319319248199463
DEBUG:root:loss:108.53323364257812 reconloss:4.283088684082031 actloss:0.650364339351654 actvqloss:3.3573169708251953
DEBUG:root:bucket 1 instance 42061
DEBUG:root:bucket 1 instance 4693
